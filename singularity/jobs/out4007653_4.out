aa
bb
Combination: 0, 6
A
B
C
lh training
gnn: 0
layers: 6
trainlh.sh model is a pialgnn
----------------------------
Start loading dataset ...
numbers 100206
numbers 100307
numbers 100408
numbers 100610
numbers 101006
numbers 101107
numbers 101309
numbers 101410
numbers 101915
numbers 102008
numbers 102311
numbers 102513
numbers 102816
numbers 103111
numbers 103414
numbers 103515
numbers 103818
numbers 104012
numbers 104416
numbers 104820
numbers 105014
numbers 105115
numbers 105216
numbers 105620
numbers 105923
numbers 106016
numbers 106319
numbers 106521
numbers 107018
numbers 107220
numbers 107321
numbers 107422
numbers 107725
numbers 108121
numbers 108222
numbers 108323
numbers 108525
numbers 108828
numbers 109123
numbers 109325
numbers 109830
numbers 110007
numbers 110411
numbers 110613
numbers 111009
numbers 111312
numbers 111413
numbers 111514
numbers 111716
numbers 112112
numbers 112314
numbers 112516
numbers 112819
numbers 112920
numbers 113215
numbers 113619
numbers 113821
numbers 113922
numbers 114217
numbers 114318
numbers 114419
numbers 114621
numbers 114823
numbers 114924
numbers 115017
numbers 115219
numbers 115320
numbers 115825
numbers 116120
numbers 116221
numbers 116524
numbers 116726
numbers 117122
numbers 117324
numbers 117930
numbers 118023
numbers 118124
numbers 118225
numbers 118528
numbers 118730
numbers 118932
numbers 119126
numbers 119732
numbers 119833
numbers 120111
numbers 120212
numbers 120515
numbers 120717
numbers 121315
numbers 121416
numbers 121618
numbers 121820
numbers 121921
numbers 122317
numbers 122620
numbers 122822
numbers 123117
numbers 123420
numbers 123521
numbers 123824
numbers 123925
numbers 124220
numbers 124422
numbers 124624
numbers 124826
numbers 125525
numbers 126325
numbers 126628
numbers 126931
numbers 127327
numbers 127630
numbers 127933
numbers 128026
numbers 128127
numbers 128329
numbers 128632
numbers 128935
numbers 129028
numbers 129129
numbers 129331
numbers 129432
numbers 129533
numbers 129634
numbers 129937
numbers 130013
numbers 130316
numbers 130417
numbers 130619
numbers 130821
numbers 130922
numbers 131217
numbers 131419
numbers 131621
numbers 131722
numbers 131823
numbers 131924
numbers 132017
numbers 132118
numbers 133019
numbers 133625
numbers 133827
numbers 133928
numbers 134021
numbers 134223
numbers 134324
numbers 134425
numbers 134728
numbers 134829
numbers 135225
numbers 135528
numbers 135730
numbers 135932
numbers 136227
numbers 136732
numbers 136833
numbers 137027
numbers 137128
numbers 137229
numbers 137633
numbers 137936
numbers 138231
numbers 138534
numbers 138837
numbers 139233
numbers 139637
numbers 139839
numbers 140117
numbers 140319
numbers 140420
numbers 140824
numbers 140925
numbers 141119
numbers 141422
numbers 141826
numbers 142424
numbers 142828
numbers 143325
numbers 143426
numbers 143527
numbers 144125
numbers 144226
numbers 144428
numbers 144731
numbers 144832
numbers 145127
numbers 145531
numbers 145834
numbers 146129
numbers 146331
numbers 146432
numbers 146533
numbers 146634
numbers 146937
numbers 147030
numbers 147737
numbers 148032
numbers 148133
numbers 148335
numbers 148436
numbers 148840
numbers 148941
numbers 149236
numbers 149337
numbers 149539
numbers 149741
numbers 149842
numbers 150019
numbers 150423
numbers 150524
numbers 150625
numbers 150726
numbers 150928
numbers 151223
numbers 151425
numbers 151526
numbers 151627
numbers 151728
numbers 151829
numbers 152831
numbers 153025
numbers 153227
numbers 153429
numbers 153631
numbers 153732
numbers 153833
numbers 154229
numbers 154431
numbers 154532
numbers 154734
numbers 154835
numbers 154936
numbers 155231
numbers 155635
numbers 155938
numbers 156031
numbers 156233
numbers 156334
numbers 156435
numbers 156536
numbers 156637
numbers 157336
numbers 157437
numbers 157942
numbers 158035
numbers 158136
numbers 158338
numbers 158540
numbers 158843
numbers 159138
numbers 159239
numbers 159340
numbers 159441
numbers 159744
numbers 159845
numbers 159946
numbers 160123
numbers 160729
numbers 160830
numbers 160931
numbers 161327
numbers 161630
numbers 161731
numbers 162026
numbers 162228
numbers 162329
numbers 162733
numbers 162935
numbers 163129
numbers 163331
numbers 163432
numbers 163836
numbers 164030
numbers 164131
numbers 164636
numbers 164939
numbers 165032
numbers 165234
numbers 165638
numbers 165840
numbers 166438
numbers 166640
numbers 167036
numbers 167238
numbers 167743
numbers 168038
numbers 168139
numbers 168240
numbers 168341
numbers 168745
numbers 169141
numbers 169343
numbers 169444
numbers 169747
numbers 169949
numbers 170631
numbers 170934
numbers 171330
numbers 171431
numbers 171532
numbers 171633
numbers 172029
numbers 172130
numbers 172332
numbers 172433
numbers 172534
numbers 172938
numbers 173132
numbers 173233
numbers 173334
numbers 173435
numbers 173536
numbers 173637
numbers 173738
numbers 173839
numbers 173940
numbers 174437
numbers 174841
numbers 175035
numbers 175237
numbers 175338
numbers 175439
numbers 175540
numbers 175742
numbers 176037
numbers 176239
numbers 176441
numbers 176542
numbers 176744
numbers 177241
numbers 177342
numbers 177645
numbers 177746
numbers 178142
numbers 178243
numbers 178647
numbers 178748
numbers 178849
numbers 178950
numbers 179245
numbers 179346
numbers 179548
numbers 179952
numbers 180129
numbers 180432
numbers 180735
numbers 180836
numbers 180937
numbers 181131
numbers 181232
numbers 181636
numbers 182032
numbers 182436
numbers 182739
numbers 182840
numbers 183034
numbers 183337
numbers 185139
numbers 185341
numbers 185442
numbers 185846
numbers 185947
numbers 186141
numbers 186444
numbers 187143
numbers 187345
numbers 187547
numbers 187850
numbers 188347
numbers 188448
numbers 188549
numbers 188751
numbers 189349
numbers 189450
numbers 190031
numbers 190132
numbers 191033
numbers 191336
numbers 191437
numbers 191841
numbers 191942
numbers 192035
numbers 192136
numbers 192439
numbers 192540
numbers 192641
numbers 192843
numbers 193239
numbers 193441
numbers 194140
numbers 194645
numbers 194746
numbers 194847
numbers 195041
numbers 195445
numbers 195647
numbers 195849
numbers 195950
numbers 196144
numbers 196346
numbers 196750
numbers 197348
numbers 197449
numbers 197550
numbers 197651
numbers 198249
numbers 198350
numbers 198451
numbers 198653
numbers 198855
numbers 199150
numbers 199251
numbers 199453
numbers 199655
numbers 199958
numbers 300618
numbers 303119
numbers 303624
numbers 304020
numbers 304727
numbers 305830
numbers 307127
numbers 308129
numbers 308331
numbers 309636
numbers 310621
numbers 311320
numbers 316633
numbers 316835
numbers 317332
numbers 318637
numbers 320826
numbers 321323
numbers 322224
numbers 329440
numbers 330324
numbers 333330
numbers 334635
numbers 336841
numbers 339847
numbers 341834
numbers 346137
numbers 346945
numbers 348545
numbers 351938
numbers 352132
numbers 352738
numbers 353740
numbers 355239
numbers 355542
numbers 356948
numbers 358144
numbers 361234
numbers 361941
numbers 365343
numbers 366042
numbers 366446
numbers 371843
numbers 377451
numbers 378857
numbers 379657
numbers 380036
numbers 381038
numbers 381543
numbers 382242
numbers 385450
numbers 386250
numbers 387959
numbers 389357
numbers 390645
numbers 391748
numbers 393247
numbers 393550
numbers 395251
numbers 395756
numbers 395958
numbers 397154
numbers 397760
numbers 397861
numbers 406432
numbers 406836
numbers 412528
numbers 414229
numbers 415837
numbers 422632
numbers 424939
numbers 429040
numbers 432332
numbers 433839
numbers 436239
numbers 436845
numbers 441939
numbers 445543
numbers 448347
numbers 449753
numbers 453441
numbers 456346
numbers 459453
numbers 465852
numbers 467351
numbers 473952
numbers 475855
numbers 479762
numbers 480141
numbers 481951
numbers 485757
numbers 486759
numbers 492754
numbers 495255
numbers 497865
numbers 499566
numbers 500222
numbers 506234
numbers 510326
numbers 512835
numbers 513736
numbers 517239
numbers 519950
numbers 520228
numbers 521331
numbers 522434
numbers 523032
numbers 524135
numbers 525541
numbers 529549
numbers 529953
numbers 530635
numbers 531536
numbers 536647
numbers 540436
numbers 541943
numbers 545345
numbers 547046
numbers 548250
numbers 549757
numbers 552544
numbers 553344
numbers 555348
numbers 555651
numbers 557857
numbers 559053
numbers 561242
numbers 561444
numbers 562345
numbers 562446
numbers 565452
numbers 566454
numbers 567052
numbers 567961
numbers 568963
numbers 570243
numbers 571144
numbers 571548
numbers 572045
numbers 573249
numbers 573451
numbers 576255
numbers 579665
numbers 579867
numbers 580044
numbers 580347
numbers 580650
numbers 580751
numbers 581349
numbers 581450
numbers 583858
numbers 584355
numbers 585256
numbers 585862
numbers 586460
numbers 587664
numbers 588565
numbers 592455
numbers 594156
numbers 597869
numbers 598568
numbers 599065
numbers 599469
numbers 599671
numbers 601127
numbers 604537
numbers 609143
numbers 611231
numbers 611938
numbers 613235
numbers 613538
numbers 614439
numbers 615744
numbers 616645
numbers 617748
numbers 618952
numbers 620434
numbers 622236
numbers 623844
numbers 626648
numbers 627549
numbers 627852
numbers 628248
numbers 633847
numbers 638049
numbers 644044
numbers 645450
numbers 645551
numbers 647858
numbers 650746
numbers 654350
numbers 654754
numbers 656253
numbers 656657
numbers 657659
numbers 660951
numbers 662551
numbers 663755
numbers 664757
numbers 665254
numbers 667056
numbers 668361
numbers 671855
numbers 672756
numbers 673455
numbers 677766
numbers 677968
numbers 679568
numbers 679770
numbers 680250
numbers 680957
numbers 683256
numbers 685058
numbers 686969
numbers 687163
numbers 690152
numbers 693461
numbers 693764
numbers 695768
numbers 700634
numbers 702133
numbers 704238
numbers 705341
numbers 706040
numbers 707749
numbers 709551
numbers 713239
numbers 715041
numbers 715647
numbers 715950
numbers 720337
numbers 724446
numbers 725751
numbers 727553
numbers 727654
numbers 729254
numbers 729557
numbers 731140
numbers 732243
numbers 733548
numbers 734045
numbers 734247
numbers 735148
numbers 737960
numbers 742549
numbers 744553
numbers 745555
numbers 748258
numbers 748662
numbers 749058
numbers 749361
numbers 751348
numbers 751550
numbers 753150
numbers 753251
numbers 756055
numbers 759869
numbers 761957
numbers 765056
numbers 766563
numbers 767464
numbers 769064
numbers 770352
numbers 771354
numbers 773257
numbers 779370
numbers 782157
numbers 782561
numbers 783462
numbers 784565
numbers 786569
numbers 788876
numbers 789373
numbers 792564
numbers 792766
numbers 792867
numbers 793465
numbers 800941
numbers 802844
numbers 803240
numbers 810439
numbers 810843
numbers 812746
numbers 814649
numbers 816653
numbers 818859
numbers 820745
numbers 825048
numbers 826353
numbers 826454
numbers 833148
numbers 833249
numbers 835657
numbers 837560
numbers 837964
numbers 841349
numbers 843151
numbers 844961
numbers 845458
numbers 849264
numbers 849971
numbers 852455
numbers 856463
numbers 856766
numbers 856968
numbers 857263
numbers 859671
numbers 861456
numbers 865363
numbers 867468
numbers 870861
numbers 871762
numbers 871964
numbers 872158
numbers 872562
numbers 872764
numbers 873968
numbers 877168
numbers 877269
numbers 878776
numbers 880157
numbers 882161
numbers 885975
numbers 887373
numbers 889579
numbers 891667
numbers 894067
numbers 894673
numbers 894774
numbers 896778
numbers 896879
numbers 898176
numbers 899885
numbers 901038
numbers 901139
numbers 901442
numbers 904044
numbers 907656
numbers 910241
numbers 910443
numbers 912447
numbers 917255
numbers 917558
numbers 919966
numbers 922854
numbers 923755
numbers 926862
numbers 927359
numbers 930449
numbers 932554
numbers 937160
numbers 942658
numbers 947668
numbers 951457
numbers 952863
numbers 953764
numbers 955465
numbers 957974
numbers 958976
numbers 959574
numbers 965367
numbers 965771
numbers 966975
numbers 972566
numbers 978578
numbers 979984
numbers 983773
numbers 984472
numbers 987983
numbers 990366
numbers 991267
numbers 992673
numbers 992774
numbers 993675
numbers 994273
numbers 996782
MSE
Finish loading dataset. There are total 790 subjects.
Training data length 632
Validation data length 158
scaling factor  0.1
----------------------------
Start loading model ...
Model is CortexGNN
NLayerGCN 6
NLayerGCN 6
Finish loading model
----------------------------
Start training 200 epochs ...
Epoch:0, training loss:0.041800239217715175
----------------------------
Start validation ...
Validation error:0.032738154082075706
Validation error:0.032738154082075706
New best model saved at epoch 0 with validation error 0.032738154082075706
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 5.23 GiB
Finish validation.
----------------------------
Epoch:1, training loss:0.031221305043731308
Epoch:2, training loss:0.02848051539091747
Epoch:3, training loss:0.02704986399393293
Epoch:4, training loss:0.02614701390443252
Epoch:5, training loss:0.025216952900555503
Epoch:6, training loss:0.024630201824268776
Epoch:7, training loss:0.024189355394131022
Epoch:8, training loss:0.023612023681944497
Epoch:9, training loss:0.02310913522091187
Epoch:10, training loss:0.022743499557829543
----------------------------
Start validation ...
Validation error:0.02235843571303766
Validation error:0.02235843571303766
New best model saved at epoch 10 with validation error 0.02235843571303766
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 5.23 GiB
Finish validation.
----------------------------
Epoch:11, training loss:0.02236476231696485
Epoch:12, training loss:0.021991231661478552
Epoch:13, training loss:0.02173626342422883
Epoch:14, training loss:0.021419396951110867
Epoch:15, training loss:0.021123673348345712
Epoch:16, training loss:0.021063346454072037
Epoch:17, training loss:0.020861476671563673
Epoch:18, training loss:0.020649338659795024
Epoch:19, training loss:0.02037991666753741
Epoch:20, training loss:0.02015071102017183
----------------------------
Start validation ...
Validation error:0.020721989707384682
Validation error:0.020721989707384682
New best model saved at epoch 20 with validation error 0.020721989707384682
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 5.23 GiB
Finish validation.
----------------------------
Epoch:21, training loss:0.020036359752316168
Epoch:22, training loss:0.019940639103326618
Epoch:23, training loss:0.019851073986685633
Epoch:24, training loss:0.01962119419292747
Epoch:25, training loss:0.01951472822995267
Epoch:26, training loss:0.019377614969764895
Epoch:27, training loss:0.019387581006953893
Epoch:28, training loss:0.019189415876812572
Epoch:29, training loss:0.019070434973492652
Epoch:30, training loss:0.018978888397340816
----------------------------
Start validation ...
Validation error:0.01927272120750026
Validation error:0.01927272120750026
New best model saved at epoch 30 with validation error 0.01927272120750026
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 5.23 GiB
Finish validation.
----------------------------
Epoch:31, training loss:0.01892151450885672
Epoch:32, training loss:0.018780235993923453
Epoch:33, training loss:0.018811648662932973
Epoch:34, training loss:0.018664827903355413
Epoch:35, training loss:0.018558705281584136
Epoch:36, training loss:0.018536548738815835
Epoch:37, training loss:0.018487266658310176
Epoch:38, training loss:0.018402941243522625
Epoch:39, training loss:0.01827418230786401
Epoch:40, training loss:0.018298896103272143
----------------------------
Start validation ...
Validation error:0.018612435016828247
Validation error:0.018612435016828247
New best model saved at epoch 40 with validation error 0.018612435016828247
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 5.23 GiB
Finish validation.
----------------------------
Epoch:41, training loss:0.018218899044043183
Epoch:42, training loss:0.018032172109778453
Epoch:43, training loss:0.01810809437780865
Epoch:44, training loss:0.01810976565532575
Epoch:45, training loss:0.017994054205585978
Epoch:46, training loss:0.0180002545386765
Epoch:47, training loss:0.017910693244584188
Epoch:48, training loss:0.0179615079711156
Epoch:49, training loss:0.017830736559367726
Epoch:50, training loss:0.01771649224477337
----------------------------
Start validation ...
Validation error:0.01853780551000109
Validation error:0.01853780551000109
New best model saved at epoch 50 with validation error 0.01853780551000109
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 5.23 GiB
Finish validation.
----------------------------
Epoch:51, training loss:0.01771668888498805
Epoch:52, training loss:0.01782604459602433
Epoch:53, training loss:0.017587671267116276
Epoch:54, training loss:0.01750697481115879
Epoch:55, training loss:0.01757012510412856
Epoch:56, training loss:0.017525598078176285
Epoch:57, training loss:0.017518078584129675
Epoch:58, training loss:0.017473448966806637
Epoch:59, training loss:0.017370439684195327
Epoch:60, training loss:0.017355157352712806
----------------------------
Start validation ...
Validation error:0.017394360520322866
Validation error:0.017394360520322866
New best model saved at epoch 60 with validation error 0.017394360520322866
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 5.23 GiB
Finish validation.
----------------------------
Epoch:61, training loss:0.01732875379627641
Epoch:62, training loss:0.017263254877238805
Epoch:63, training loss:0.017215921325444042
Epoch:64, training loss:0.01724957830797221
Epoch:65, training loss:0.01720220092212475
Epoch:66, training loss:0.017218190467845694
Epoch:67, training loss:0.01713416757963928
Epoch:68, training loss:0.017086637638143817
Epoch:69, training loss:0.01713097623631924
Epoch:70, training loss:0.01706743774245953
----------------------------
Start validation ...
Validation error:0.017202644709120446
Validation error:0.017202644709120446
New best model saved at epoch 70 with validation error 0.017202644709120446
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 5.23 GiB
Finish validation.
----------------------------
Epoch:71, training loss:0.017025722898071326
Epoch:72, training loss:0.017028603782358615
Epoch:73, training loss:0.01691091084510937
Epoch:74, training loss:0.01702831949172188
Epoch:75, training loss:0.016929067630037854
Epoch:76, training loss:0.01688114273998462
Epoch:77, training loss:0.016887332159507124
Epoch:78, training loss:0.01685224927496165
Epoch:79, training loss:0.016878767266185788
Epoch:80, training loss:0.016809530731561724
----------------------------
Start validation ...
Validation error:0.01719622344037966
Validation error:0.01719622344037966
New best model saved at epoch 80 with validation error 0.01719622344037966
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 5.23 GiB
Finish validation.
----------------------------
Epoch:81, training loss:0.016800544034583566
Epoch:82, training loss:0.016715725229557932
Epoch:83, training loss:0.01666317009396521
Epoch:84, training loss:0.01673877531739211
Epoch:85, training loss:0.016676353610450802
Epoch:86, training loss:0.01669054551792767
Epoch:87, training loss:0.016688654103457833
Epoch:88, training loss:0.016637177423196786
Epoch:89, training loss:0.016608426525681928
Epoch:90, training loss:0.016575744792618613
----------------------------
Start validation ...
Validation error:0.01746492957861363
Validation error:0.01746492957861363
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 5.23 GiB
Finish validation.
----------------------------
Epoch:91, training loss:0.016541956570235234
Epoch:92, training loss:0.016509371286529247
Epoch:93, training loss:0.016550917644053698
Epoch:94, training loss:0.016484934624425972
Epoch:95, training loss:0.016515311278119872
Epoch:96, training loss:0.016425159146797052
Epoch:97, training loss:0.016460400092403724
Epoch:98, training loss:0.01640146672047816
Epoch:99, training loss:0.016446176698266327
Epoch:100, training loss:0.016429796089901576
----------------------------
Start validation ...
Validation error:0.016330316037977043
Validation error:0.016330316037977043
New best model saved at epoch 100 with validation error 0.016330316037977043
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 5.23 GiB
Finish validation.
----------------------------
Epoch:101, training loss:0.016399918928671674
Epoch:102, training loss:0.01638560229617678
Epoch:103, training loss:0.01639022537996356
Epoch:104, training loss:0.01629532340330461
Epoch:105, training loss:0.01630498572323424
Epoch:106, training loss:0.0162656162497057
Epoch:107, training loss:0.016328025261482484
Epoch:108, training loss:0.01624316171613298
Epoch:109, training loss:0.01621241686582754
Epoch:110, training loss:0.01621377059181893
----------------------------
Start validation ...
Validation error:0.01736236588817231
Validation error:0.01736236588817231
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 5.23 GiB
Finish validation.
----------------------------
Epoch:111, training loss:0.01619052340400323
Epoch:112, training loss:0.016311310253789815
Epoch:113, training loss:0.01617652625641255
Epoch:114, training loss:0.01612292636109257
Epoch:115, training loss:0.016080870371182224
Epoch:116, training loss:0.01610677139656736
Epoch:117, training loss:0.01611451691759255
Epoch:118, training loss:0.016118685486490685
Epoch:119, training loss:0.016128913212060645
Epoch:120, training loss:0.016086855353610707
----------------------------
Start validation ...
Validation error:0.01621452633503683
Validation error:0.01621452633503683
New best model saved at epoch 120 with validation error 0.01621452633503683
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 5.23 GiB
Finish validation.
----------------------------
Epoch:121, training loss:0.016166954538549144
Epoch:122, training loss:0.016053139957116
Epoch:123, training loss:0.01604689032582071
Epoch:124, training loss:0.01606396519537732
Epoch:125, training loss:0.015950206282572186
Epoch:126, training loss:0.01597242183759337
Epoch:127, training loss:0.015986862473036576
Epoch:128, training loss:0.015977657846575958
Epoch:129, training loss:0.015946071001088035
Epoch:130, training loss:0.01592172246390977
----------------------------
Start validation ...
Validation error:0.016595489893674473
Validation error:0.016595489893674473
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 5.23 GiB
Finish validation.
----------------------------
Epoch:131, training loss:0.015956337815681117
Epoch:132, training loss:0.015918595958029545
Epoch:133, training loss:0.015962380883460747
Epoch:134, training loss:0.015945826315238505
Epoch:135, training loss:0.015883343146901718
Epoch:136, training loss:0.015873675465972834
Epoch:137, training loss:0.015805469382306727
Epoch:138, training loss:0.01583803004932979
Epoch:139, training loss:0.015861071254232827
Epoch:140, training loss:0.01583092714824914
----------------------------
Start validation ...
Validation error:0.016002268218022735
Validation error:0.016002268218022735
New best model saved at epoch 140 with validation error 0.016002268218022735
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 5.23 GiB
Finish validation.
----------------------------
Epoch:141, training loss:0.015786797542101407
Epoch:142, training loss:0.015871152701740495
Epoch:143, training loss:0.015853575516279927
Epoch:144, training loss:0.015758310611171153
Epoch:145, training loss:0.01585521688390099
Epoch:146, training loss:0.01570557444238493
Epoch:147, training loss:0.015774274551415744
Epoch:148, training loss:0.015749131886382835
Epoch:149, training loss:0.015734900515585477
Epoch:150, training loss:0.01568834340683173
----------------------------
Start validation ...
Validation error:0.016263088535611765
Validation error:0.016263088535611765
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 5.23 GiB
Finish validation.
----------------------------
Epoch:151, training loss:0.015765343551064216
Epoch:152, training loss:0.015650797490902906
Epoch:153, training loss:0.015698396350268887
Epoch:154, training loss:0.015728856988039008
Epoch:155, training loss:0.01568441166353848
Epoch:156, training loss:0.01574046342321259
Epoch:157, training loss:0.015634034997547824
Epoch:158, training loss:0.01566050190012902
Epoch:159, training loss:0.015601493844090477
Epoch:160, training loss:0.015557522067646908
----------------------------
Start validation ...
Validation error:0.01591320675385149
Validation error:0.01591320675385149
New best model saved at epoch 160 with validation error 0.01591320675385149
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 5.23 GiB
Finish validation.
----------------------------
Epoch:161, training loss:0.015573333802963076
Epoch:162, training loss:0.015603426027500743
Epoch:163, training loss:0.015604959540010158
Epoch:164, training loss:0.015557870601857954
Epoch:165, training loss:0.01563303351632166
Epoch:166, training loss:0.015581855302841603
Epoch:167, training loss:0.01556465634044637
Epoch:168, training loss:0.015488451382121708
Epoch:169, training loss:0.015547014068505621
Epoch:170, training loss:0.015546378206544191
----------------------------
Start validation ...
Validation error:0.016092505753983424
Validation error:0.016092505753983424
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 5.23 GiB
Finish validation.
----------------------------
Epoch:171, training loss:0.015501943835399197
Epoch:172, training loss:0.015494808638645219
Epoch:173, training loss:0.01544952694521156
Epoch:174, training loss:0.015517136874856263
Epoch:175, training loss:0.015464164079402726
Epoch:176, training loss:0.015476035785307235
Epoch:177, training loss:0.015459640706075898
Epoch:178, training loss:0.015442510686602585
Epoch:179, training loss:0.015470071691324156
Epoch:180, training loss:0.015409021921267238
----------------------------
Start validation ...
Validation error:0.015704176524253207
Validation error:0.015704176524253207
New best model saved at epoch 180 with validation error 0.015704176524253207
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 5.23 GiB
Finish validation.
----------------------------
Epoch:181, training loss:0.015407147174818983
Epoch:182, training loss:0.015403344158873056
Epoch:183, training loss:0.015419608928098143
Epoch:184, training loss:0.015427650446131166
Epoch:185, training loss:0.015396453891114532
Epoch:186, training loss:0.015346409191518928
Epoch:187, training loss:0.015420109942802995
Epoch:188, training loss:0.015400793645059384
Epoch:189, training loss:0.01535966658605192
Epoch:190, training loss:0.015411091457073919
----------------------------
Start validation ...
Validation error:0.015905226297865185
Validation error:0.015905226297865185
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 5.23 GiB
Finish validation.
----------------------------
Epoch:191, training loss:0.015287486513593245
Epoch:192, training loss:0.015397121314890683
Epoch:193, training loss:0.015305590998569998
Epoch:194, training loss:0.015312386558780188
Epoch:195, training loss:0.015376215768223511
Epoch:196, training loss:0.015305443339733571
Epoch:197, training loss:0.015245123004505434
Epoch:198, training loss:0.015280486295247286
Epoch:199, training loss:0.015289218776529254
Epoch:200, training loss:0.015228378366902943
----------------------------
Start validation ...
Validation error:0.01588602010985907
Validation error:0.01588602010985907
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 5.23 GiB
Finish validation.
----------------------------
Finish training.
----------------------------
D
CC

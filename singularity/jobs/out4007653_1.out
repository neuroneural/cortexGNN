aa
bb
Combination: 0, 3
A
B
C
lh training
gnn: 0
layers: 3
trainlh.sh model is a pialgnn
----------------------------
Start loading dataset ...
numbers 100206
numbers 100307
numbers 100408
numbers 100610
numbers 101006
numbers 101107
numbers 101309
numbers 101410
numbers 101915
numbers 102008
numbers 102311
numbers 102513
numbers 102816
numbers 103111
numbers 103414
numbers 103515
numbers 103818
numbers 104012
numbers 104416
numbers 104820
numbers 105014
numbers 105115
numbers 105216
numbers 105620
numbers 105923
numbers 106016
numbers 106319
numbers 106521
numbers 107018
numbers 107220
numbers 107321
numbers 107422
numbers 107725
numbers 108121
numbers 108222
numbers 108323
numbers 108525
numbers 108828
numbers 109123
numbers 109325
numbers 109830
numbers 110007
numbers 110411
numbers 110613
numbers 111009
numbers 111312
numbers 111413
numbers 111514
numbers 111716
numbers 112112
numbers 112314
numbers 112516
numbers 112819
numbers 112920
numbers 113215
numbers 113619
numbers 113821
numbers 113922
numbers 114217
numbers 114318
numbers 114419
numbers 114621
numbers 114823
numbers 114924
numbers 115017
numbers 115219
numbers 115320
numbers 115825
numbers 116120
numbers 116221
numbers 116524
numbers 116726
numbers 117122
numbers 117324
numbers 117930
numbers 118023
numbers 118124
numbers 118225
numbers 118528
numbers 118730
numbers 118932
numbers 119126
numbers 119732
numbers 119833
numbers 120111
numbers 120212
numbers 120515
numbers 120717
numbers 121315
numbers 121416
numbers 121618
numbers 121820
numbers 121921
numbers 122317
numbers 122620
numbers 122822
numbers 123117
numbers 123420
numbers 123521
numbers 123824
numbers 123925
numbers 124220
numbers 124422
numbers 124624
numbers 124826
numbers 125525
numbers 126325
numbers 126628
numbers 126931
numbers 127327
numbers 127630
numbers 127933
numbers 128026
numbers 128127
numbers 128329
numbers 128632
numbers 128935
numbers 129028
numbers 129129
numbers 129331
numbers 129432
numbers 129533
numbers 129634
numbers 129937
numbers 130013
numbers 130316
numbers 130417
numbers 130619
numbers 130821
numbers 130922
numbers 131217
numbers 131419
numbers 131621
numbers 131722
numbers 131823
numbers 131924
numbers 132017
numbers 132118
numbers 133019
numbers 133625
numbers 133827
numbers 133928
numbers 134021
numbers 134223
numbers 134324
numbers 134425
numbers 134728
numbers 134829
numbers 135225
numbers 135528
numbers 135730
numbers 135932
numbers 136227
numbers 136732
numbers 136833
numbers 137027
numbers 137128
numbers 137229
numbers 137633
numbers 137936
numbers 138231
numbers 138534
numbers 138837
numbers 139233
numbers 139637
numbers 139839
numbers 140117
numbers 140319
numbers 140420
numbers 140824
numbers 140925
numbers 141119
numbers 141422
numbers 141826
numbers 142424
numbers 142828
numbers 143325
numbers 143426
numbers 143527
numbers 144125
numbers 144226
numbers 144428
numbers 144731
numbers 144832
numbers 145127
numbers 145531
numbers 145834
numbers 146129
numbers 146331
numbers 146432
numbers 146533
numbers 146634
numbers 146937
numbers 147030
numbers 147737
numbers 148032
numbers 148133
numbers 148335
numbers 148436
numbers 148840
numbers 148941
numbers 149236
numbers 149337
numbers 149539
numbers 149741
numbers 149842
numbers 150019
numbers 150423
numbers 150524
numbers 150625
numbers 150726
numbers 150928
numbers 151223
numbers 151425
numbers 151526
numbers 151627
numbers 151728
numbers 151829
numbers 152831
numbers 153025
numbers 153227
numbers 153429
numbers 153631
numbers 153732
numbers 153833
numbers 154229
numbers 154431
numbers 154532
numbers 154734
numbers 154835
numbers 154936
numbers 155231
numbers 155635
numbers 155938
numbers 156031
numbers 156233
numbers 156334
numbers 156435
numbers 156536
numbers 156637
numbers 157336
numbers 157437
numbers 157942
numbers 158035
numbers 158136
numbers 158338
numbers 158540
numbers 158843
numbers 159138
numbers 159239
numbers 159340
numbers 159441
numbers 159744
numbers 159845
numbers 159946
numbers 160123
numbers 160729
numbers 160830
numbers 160931
numbers 161327
numbers 161630
numbers 161731
numbers 162026
numbers 162228
numbers 162329
numbers 162733
numbers 162935
numbers 163129
numbers 163331
numbers 163432
numbers 163836
numbers 164030
numbers 164131
numbers 164636
numbers 164939
numbers 165032
numbers 165234
numbers 165638
numbers 165840
numbers 166438
numbers 166640
numbers 167036
numbers 167238
numbers 167743
numbers 168038
numbers 168139
numbers 168240
numbers 168341
numbers 168745
numbers 169141
numbers 169343
numbers 169444
numbers 169747
numbers 169949
numbers 170631
numbers 170934
numbers 171330
numbers 171431
numbers 171532
numbers 171633
numbers 172029
numbers 172130
numbers 172332
numbers 172433
numbers 172534
numbers 172938
numbers 173132
numbers 173233
numbers 173334
numbers 173435
numbers 173536
numbers 173637
numbers 173738
numbers 173839
numbers 173940
numbers 174437
numbers 174841
numbers 175035
numbers 175237
numbers 175338
numbers 175439
numbers 175540
numbers 175742
numbers 176037
numbers 176239
numbers 176441
numbers 176542
numbers 176744
numbers 177241
numbers 177342
numbers 177645
numbers 177746
numbers 178142
numbers 178243
numbers 178647
numbers 178748
numbers 178849
numbers 178950
numbers 179245
numbers 179346
numbers 179548
numbers 179952
numbers 180129
numbers 180432
numbers 180735
numbers 180836
numbers 180937
numbers 181131
numbers 181232
numbers 181636
numbers 182032
numbers 182436
numbers 182739
numbers 182840
numbers 183034
numbers 183337
numbers 185139
numbers 185341
numbers 185442
numbers 185846
numbers 185947
numbers 186141
numbers 186444
numbers 187143
numbers 187345
numbers 187547
numbers 187850
numbers 188347
numbers 188448
numbers 188549
numbers 188751
numbers 189349
numbers 189450
numbers 190031
numbers 190132
numbers 191033
numbers 191336
numbers 191437
numbers 191841
numbers 191942
numbers 192035
numbers 192136
numbers 192439
numbers 192540
numbers 192641
numbers 192843
numbers 193239
numbers 193441
numbers 194140
numbers 194645
numbers 194746
numbers 194847
numbers 195041
numbers 195445
numbers 195647
numbers 195849
numbers 195950
numbers 196144
numbers 196346
numbers 196750
numbers 197348
numbers 197449
numbers 197550
numbers 197651
numbers 198249
numbers 198350
numbers 198451
numbers 198653
numbers 198855
numbers 199150
numbers 199251
numbers 199453
numbers 199655
numbers 199958
numbers 300618
numbers 303119
numbers 303624
numbers 304020
numbers 304727
numbers 305830
numbers 307127
numbers 308129
numbers 308331
numbers 309636
numbers 310621
numbers 311320
numbers 316633
numbers 316835
numbers 317332
numbers 318637
numbers 320826
numbers 321323
numbers 322224
numbers 329440
numbers 330324
numbers 333330
numbers 334635
numbers 336841
numbers 339847
numbers 341834
numbers 346137
numbers 346945
numbers 348545
numbers 351938
numbers 352132
numbers 352738
numbers 353740
numbers 355239
numbers 355542
numbers 356948
numbers 358144
numbers 361234
numbers 361941
numbers 365343
numbers 366042
numbers 366446
numbers 371843
numbers 377451
numbers 378857
numbers 379657
numbers 380036
numbers 381038
numbers 381543
numbers 382242
numbers 385450
numbers 386250
numbers 387959
numbers 389357
numbers 390645
numbers 391748
numbers 393247
numbers 393550
numbers 395251
numbers 395756
numbers 395958
numbers 397154
numbers 397760
numbers 397861
numbers 406432
numbers 406836
numbers 412528
numbers 414229
numbers 415837
numbers 422632
numbers 424939
numbers 429040
numbers 432332
numbers 433839
numbers 436239
numbers 436845
numbers 441939
numbers 445543
numbers 448347
numbers 449753
numbers 453441
numbers 456346
numbers 459453
numbers 465852
numbers 467351
numbers 473952
numbers 475855
numbers 479762
numbers 480141
numbers 481951
numbers 485757
numbers 486759
numbers 492754
numbers 495255
numbers 497865
numbers 499566
numbers 500222
numbers 506234
numbers 510326
numbers 512835
numbers 513736
numbers 517239
numbers 519950
numbers 520228
numbers 521331
numbers 522434
numbers 523032
numbers 524135
numbers 525541
numbers 529549
numbers 529953
numbers 530635
numbers 531536
numbers 536647
numbers 540436
numbers 541943
numbers 545345
numbers 547046
numbers 548250
numbers 549757
numbers 552544
numbers 553344
numbers 555348
numbers 555651
numbers 557857
numbers 559053
numbers 561242
numbers 561444
numbers 562345
numbers 562446
numbers 565452
numbers 566454
numbers 567052
numbers 567961
numbers 568963
numbers 570243
numbers 571144
numbers 571548
numbers 572045
numbers 573249
numbers 573451
numbers 576255
numbers 579665
numbers 579867
numbers 580044
numbers 580347
numbers 580650
numbers 580751
numbers 581349
numbers 581450
numbers 583858
numbers 584355
numbers 585256
numbers 585862
numbers 586460
numbers 587664
numbers 588565
numbers 592455
numbers 594156
numbers 597869
numbers 598568
numbers 599065
numbers 599469
numbers 599671
numbers 601127
numbers 604537
numbers 609143
numbers 611231
numbers 611938
numbers 613235
numbers 613538
numbers 614439
numbers 615744
numbers 616645
numbers 617748
numbers 618952
numbers 620434
numbers 622236
numbers 623844
numbers 626648
numbers 627549
numbers 627852
numbers 628248
numbers 633847
numbers 638049
numbers 644044
numbers 645450
numbers 645551
numbers 647858
numbers 650746
numbers 654350
numbers 654754
numbers 656253
numbers 656657
numbers 657659
numbers 660951
numbers 662551
numbers 663755
numbers 664757
numbers 665254
numbers 667056
numbers 668361
numbers 671855
numbers 672756
numbers 673455
numbers 677766
numbers 677968
numbers 679568
numbers 679770
numbers 680250
numbers 680957
numbers 683256
numbers 685058
numbers 686969
numbers 687163
numbers 690152
numbers 693461
numbers 693764
numbers 695768
numbers 700634
numbers 702133
numbers 704238
numbers 705341
numbers 706040
numbers 707749
numbers 709551
numbers 713239
numbers 715041
numbers 715647
numbers 715950
numbers 720337
numbers 724446
numbers 725751
numbers 727553
numbers 727654
numbers 729254
numbers 729557
numbers 731140
numbers 732243
numbers 733548
numbers 734045
numbers 734247
numbers 735148
numbers 737960
numbers 742549
numbers 744553
numbers 745555
numbers 748258
numbers 748662
numbers 749058
numbers 749361
numbers 751348
numbers 751550
numbers 753150
numbers 753251
numbers 756055
numbers 759869
numbers 761957
numbers 765056
numbers 766563
numbers 767464
numbers 769064
numbers 770352
numbers 771354
numbers 773257
numbers 779370
numbers 782157
numbers 782561
numbers 783462
numbers 784565
numbers 786569
numbers 788876
numbers 789373
numbers 792564
numbers 792766
numbers 792867
numbers 793465
numbers 800941
numbers 802844
numbers 803240
numbers 810439
numbers 810843
numbers 812746
numbers 814649
numbers 816653
numbers 818859
numbers 820745
numbers 825048
numbers 826353
numbers 826454
numbers 833148
numbers 833249
numbers 835657
numbers 837560
numbers 837964
numbers 841349
numbers 843151
numbers 844961
numbers 845458
numbers 849264
numbers 849971
numbers 852455
numbers 856463
numbers 856766
numbers 856968
numbers 857263
numbers 859671
numbers 861456
numbers 865363
numbers 867468
numbers 870861
numbers 871762
numbers 871964
numbers 872158
numbers 872562
numbers 872764
numbers 873968
numbers 877168
numbers 877269
numbers 878776
numbers 880157
numbers 882161
numbers 885975
numbers 887373
numbers 889579
numbers 891667
numbers 894067
numbers 894673
numbers 894774
numbers 896778
numbers 896879
numbers 898176
numbers 899885
numbers 901038
numbers 901139
numbers 901442
numbers 904044
numbers 907656
numbers 910241
numbers 910443
numbers 912447
numbers 917255
numbers 917558
numbers 919966
numbers 922854
numbers 923755
numbers 926862
numbers 927359
numbers 930449
numbers 932554
numbers 937160
numbers 942658
numbers 947668
numbers 951457
numbers 952863
numbers 953764
numbers 955465
numbers 957974
numbers 958976
numbers 959574
numbers 965367
numbers 965771
numbers 966975
numbers 972566
numbers 978578
numbers 979984
numbers 983773
numbers 984472
numbers 987983
numbers 990366
numbers 991267
numbers 992673
numbers 992774
numbers 993675
numbers 994273
numbers 996782
MSE
Finish loading dataset. There are total 790 subjects.
Training data length 632
Validation data length 158
scaling factor  0.1
----------------------------
Start loading model ...
Model is CortexGNN
NLayerGCN 3
NLayerGCN 3
Finish loading model
----------------------------
Start training 200 epochs ...
Epoch:0, training loss:0.05114402324904369
----------------------------
Start validation ...
Validation error:0.04308329291547401
Validation error:0.04308329291547401
New best model saved at epoch 0 with validation error 0.04308329291547401
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 2.94 GiB
Finish validation.
----------------------------
Epoch:1, training loss:0.0409296854587767
Epoch:2, training loss:0.038221187712742556
Epoch:3, training loss:0.03674665319473966
Epoch:4, training loss:0.03541016158105546
Epoch:5, training loss:0.034458506566507716
Epoch:6, training loss:0.03365918185821251
Epoch:7, training loss:0.033084391147676334
Epoch:8, training loss:0.03255851280910871
Epoch:9, training loss:0.03202166398574563
Epoch:10, training loss:0.03164641608637345
----------------------------
Start validation ...
Validation error:0.03140817306747165
Validation error:0.03140817306747165
New best model saved at epoch 10 with validation error 0.03140817306747165
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 2.94 GiB
Finish validation.
----------------------------
Epoch:11, training loss:0.031255682956875315
Epoch:12, training loss:0.031010445092415698
Epoch:13, training loss:0.030708489273497952
Epoch:14, training loss:0.030401918155883875
Epoch:15, training loss:0.03015273382675044
Epoch:16, training loss:0.029963796085949186
Epoch:17, training loss:0.02971951891019752
Epoch:18, training loss:0.029565791113160645
Epoch:19, training loss:0.029201589845993286
Epoch:20, training loss:0.028981730577689182
----------------------------
Start validation ...
Validation error:0.028854525671635246
Validation error:0.028854525671635246
New best model saved at epoch 20 with validation error 0.028854525671635246
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 2.94 GiB
Finish validation.
----------------------------
Epoch:21, training loss:0.028904958740112525
Epoch:22, training loss:0.028679276135738327
Epoch:23, training loss:0.02851146124185452
Epoch:24, training loss:0.02829058392008743
Epoch:25, training loss:0.028249744694279152
Epoch:26, training loss:0.028025959804064676
Epoch:27, training loss:0.027918816871257333
Epoch:28, training loss:0.027715823993299016
Epoch:29, training loss:0.02756413804437918
Epoch:30, training loss:0.027484860636671132
----------------------------
Start validation ...
Validation error:0.028240113719543325
Validation error:0.028240113719543325
New best model saved at epoch 30 with validation error 0.028240113719543325
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 2.94 GiB
Finish validation.
----------------------------
Epoch:31, training loss:0.02733468453847815
Epoch:32, training loss:0.02727451145684323
Epoch:33, training loss:0.027119295179395923
Epoch:34, training loss:0.026970331669089537
Epoch:35, training loss:0.026849662501930813
Epoch:36, training loss:0.02665367063217431
Epoch:37, training loss:0.026830596227458196
Epoch:38, training loss:0.026630681111253326
Epoch:39, training loss:0.026453358250894125
Epoch:40, training loss:0.02632930293042637
----------------------------
Start validation ...
Validation error:0.02700948497115434
Validation error:0.02700948497115434
New best model saved at epoch 40 with validation error 0.02700948497115434
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 2.94 GiB
Finish validation.
----------------------------
Epoch:41, training loss:0.02631187531802379
Epoch:42, training loss:0.02619198588890177
Epoch:43, training loss:0.026149237870321244
Epoch:44, training loss:0.026019754433485715
Epoch:45, training loss:0.025983649742188333
Epoch:46, training loss:0.025946177689570794
Epoch:47, training loss:0.025818347904383192
Epoch:48, training loss:0.025756040788432466
Epoch:49, training loss:0.025587022501998877
Epoch:50, training loss:0.025500822485177013
----------------------------
Start validation ...
Validation error:0.026776627908590474
Validation error:0.026776627908590474
New best model saved at epoch 50 with validation error 0.026776627908590474
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 2.94 GiB
Finish validation.
----------------------------
Epoch:51, training loss:0.025606244890891677
Epoch:52, training loss:0.025372162334550218
Epoch:53, training loss:0.025383689210903417
Epoch:54, training loss:0.025311579647815868
Epoch:55, training loss:0.02527064314890134
Epoch:56, training loss:0.025140328822020865
Epoch:57, training loss:0.02518939258990503
Epoch:58, training loss:0.025043922190589808
Epoch:59, training loss:0.025020667793865824
Epoch:60, training loss:0.024947965317228926
----------------------------
Start validation ...
Validation error:0.025429965362330026
Validation error:0.025429965362330026
New best model saved at epoch 60 with validation error 0.025429965362330026
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 2.94 GiB
Finish validation.
----------------------------
Epoch:61, training loss:0.024766536759613437
Epoch:62, training loss:0.024840593002029236
Epoch:63, training loss:0.024761690277771295
Epoch:64, training loss:0.02470316020241361
Epoch:65, training loss:0.0246666785140958
Epoch:66, training loss:0.024636505899620773
Epoch:67, training loss:0.024605545265411463
Epoch:68, training loss:0.0245273832785838
Epoch:69, training loss:0.02449236890666564
Epoch:70, training loss:0.024332848763612063
----------------------------
Start validation ...
Validation error:0.024586024682355833
Validation error:0.024586024682355833
New best model saved at epoch 70 with validation error 0.024586024682355833
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 2.94 GiB
Finish validation.
----------------------------
Epoch:71, training loss:0.024366993271403865
Epoch:72, training loss:0.02431434797288119
Epoch:73, training loss:0.024244811945842413
Epoch:74, training loss:0.02420702853676262
Epoch:75, training loss:0.024224092461805367
Epoch:76, training loss:0.024125910847436025
Epoch:77, training loss:0.024066386877005047
Epoch:78, training loss:0.024005821169224343
Epoch:79, training loss:0.023984375008959558
Epoch:80, training loss:0.023957860040112952
----------------------------
Start validation ...
Validation error:0.02453619957300304
Validation error:0.02453619957300304
New best model saved at epoch 80 with validation error 0.02453619957300304
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 2.94 GiB
Finish validation.
----------------------------
Epoch:81, training loss:0.023964064911927416
Epoch:82, training loss:0.02388222950593203
Epoch:83, training loss:0.023852046296189103
Epoch:84, training loss:0.02378787850088711
Epoch:85, training loss:0.023771053268515235
Epoch:86, training loss:0.023745640572985706
Epoch:87, training loss:0.023736135462369724
Epoch:88, training loss:0.023647716955600095
Epoch:89, training loss:0.02364357921613168
Epoch:90, training loss:0.023550160910014675
----------------------------
Start validation ...
Validation error:0.024833417957342122
Validation error:0.024833417957342122
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 2.94 GiB
Finish validation.
----------------------------
Epoch:91, training loss:0.023567694410257325
Epoch:92, training loss:0.023479282154548396
Epoch:93, training loss:0.02352957685973165
Epoch:94, training loss:0.02340773569974058
Epoch:95, training loss:0.023492832167097664
Epoch:96, training loss:0.023294171739864766
Epoch:97, training loss:0.02342847414326536
Epoch:98, training loss:0.02331538849121219
Epoch:99, training loss:0.023368224312987507
Epoch:100, training loss:0.02324449603410461
----------------------------
Start validation ...
Validation error:0.023665773741240743
Validation error:0.023665773741240743
New best model saved at epoch 100 with validation error 0.023665773741240743
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 2.94 GiB
Finish validation.
----------------------------
Epoch:101, training loss:0.023258074080642267
Epoch:102, training loss:0.023224295862608508
Epoch:103, training loss:0.02318058346834364
Epoch:104, training loss:0.023113395788860094
Epoch:105, training loss:0.02307434538320367
Epoch:106, training loss:0.02302111758956615
Epoch:107, training loss:0.023059856246779614
Epoch:108, training loss:0.023010680242736316
Epoch:109, training loss:0.022972275558977
Epoch:110, training loss:0.022959112740840903
----------------------------
Start validation ...
Validation error:0.02340557750408785
Validation error:0.02340557750408785
New best model saved at epoch 110 with validation error 0.02340557750408785
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 2.94 GiB
Finish validation.
----------------------------
Epoch:111, training loss:0.022956418312638054
Epoch:112, training loss:0.022921417347638855
Epoch:113, training loss:0.02291908744380727
Epoch:114, training loss:0.022935940863423144
Epoch:115, training loss:0.022784958443238953
Epoch:116, training loss:0.022877555113592293
Epoch:117, training loss:0.02286892070706132
Epoch:118, training loss:0.022833101536866417
Epoch:119, training loss:0.022800679928682083
Epoch:120, training loss:0.02277851301610847
----------------------------
Start validation ...
Validation error:0.023854495203004606
Validation error:0.023854495203004606
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 2.94 GiB
Finish validation.
----------------------------
Epoch:121, training loss:0.022686566656478977
Epoch:122, training loss:0.022598103446225766
Epoch:123, training loss:0.022685533144829583
Epoch:124, training loss:0.022714958045796693
Epoch:125, training loss:0.02261823667743821
Epoch:126, training loss:0.02269786206085848
Epoch:127, training loss:0.022608201269979908
Epoch:128, training loss:0.022515623220183616
Epoch:129, training loss:0.022549604613899807
Epoch:130, training loss:0.022521536384673812
----------------------------
Start validation ...
Validation error:0.02297942111669462
Validation error:0.02297942111669462
New best model saved at epoch 130 with validation error 0.02297942111669462
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 2.94 GiB
Finish validation.
----------------------------
Epoch:131, training loss:0.022611192669247902
Epoch:132, training loss:0.022471252799364207
Epoch:133, training loss:0.022423696604003257
Epoch:134, training loss:0.022370660768916147
Epoch:135, training loss:0.022450682235575174
Epoch:136, training loss:0.022400869504560397
Epoch:137, training loss:0.02236972652269598
Epoch:138, training loss:0.022407937889234928
Epoch:139, training loss:0.02232634933677184
Epoch:140, training loss:0.02234015144006927
----------------------------
Start validation ...
Validation error:0.02269034666492592
Validation error:0.02269034666492592
New best model saved at epoch 140 with validation error 0.02269034666492592
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 2.94 GiB
Finish validation.
----------------------------
Epoch:141, training loss:0.02228490015067443
Epoch:142, training loss:0.022276876361663395
Epoch:143, training loss:0.022256375912317557
Epoch:144, training loss:0.022259236678858346
Epoch:145, training loss:0.0222472250667884
Epoch:146, training loss:0.022191643169668467
Epoch:147, training loss:0.02230379792354718
Epoch:148, training loss:0.022153736755275464
Epoch:149, training loss:0.022195871904657424
Epoch:150, training loss:0.022081359504733847
----------------------------
Start validation ...
Validation error:0.022280748426631282
Validation error:0.022280748426631282
New best model saved at epoch 150 with validation error 0.022280748426631282
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 2.94 GiB
Finish validation.
----------------------------
Epoch:151, training loss:0.022198545301474536
Epoch:152, training loss:0.022135823092694525
Epoch:153, training loss:0.022093294347530303
Epoch:154, training loss:0.02206517464504872
Epoch:155, training loss:0.022055471923107965
Epoch:156, training loss:0.02212619616744356
Epoch:157, training loss:0.021960994278823462
Epoch:158, training loss:0.022042436548803425
Epoch:159, training loss:0.021977604782397422
Epoch:160, training loss:0.022028084959292524
----------------------------
Start validation ...
Validation error:0.022059345181701304
Validation error:0.022059345181701304
New best model saved at epoch 160 with validation error 0.022059345181701304
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 2.94 GiB
Finish validation.
----------------------------
Epoch:161, training loss:0.02194229656052363
Epoch:162, training loss:0.02197960355389816
Epoch:163, training loss:0.02193271386425329
Epoch:164, training loss:0.021855927340662742
Epoch:165, training loss:0.021962507507068258
Epoch:166, training loss:0.02198246976101323
Epoch:167, training loss:0.02182728742378988
Epoch:168, training loss:0.02188917364382857
Epoch:169, training loss:0.021793093679685006
Epoch:170, training loss:0.02184874905108274
----------------------------
Start validation ...
Validation error:0.022855617388894287
Validation error:0.022855617388894287
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 2.94 GiB
Finish validation.
----------------------------
Epoch:171, training loss:0.021855270696355948
Epoch:172, training loss:0.021837150091541153
Epoch:173, training loss:0.021765046234277986
Epoch:174, training loss:0.0218063042222086
Epoch:175, training loss:0.02184531377345512
Epoch:176, training loss:0.02168570903625009
Epoch:177, training loss:0.021783506689310263
Epoch:178, training loss:0.021676491639470753
Epoch:179, training loss:0.02170545370259051
Epoch:180, training loss:0.021677205984516047
----------------------------
Start validation ...
Validation error:0.022277372688809527
Validation error:0.022277372688809527
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 2.94 GiB
Finish validation.
----------------------------
Epoch:181, training loss:0.0216517139526815
Epoch:182, training loss:0.021776043208716792
Epoch:183, training loss:0.02163145899230355
Epoch:184, training loss:0.02164149755918527
Epoch:185, training loss:0.021655018005190017
Epoch:186, training loss:0.02161399630794325
Epoch:187, training loss:0.021678176086655336
Epoch:188, training loss:0.02163340448979524
Epoch:189, training loss:0.021690730530108455
Epoch:190, training loss:0.021576037689383272
----------------------------
Start validation ...
Validation error:0.02324270300237061
Validation error:0.02324270300237061
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 2.94 GiB
Finish validation.
----------------------------
Epoch:191, training loss:0.021537514574401364
Epoch:192, training loss:0.02155418072744638
Epoch:193, training loss:0.021520847864331134
Epoch:194, training loss:0.021578423174899778
Epoch:195, training loss:0.02144462369747837
Epoch:196, training loss:0.021594126163569243
Epoch:197, training loss:0.021454370963752648
Epoch:198, training loss:0.021540482876280062
Epoch:199, training loss:0.021467494769493424
Epoch:200, training loss:0.02144190575338051
----------------------------
Start validation ...
Validation error:0.021518252200529546
Validation error:0.021518252200529546
New best model saved at epoch 200 with validation error 0.021518252200529546
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 2.94 GiB
Finish validation.
----------------------------
Finish training.
----------------------------
D
CC

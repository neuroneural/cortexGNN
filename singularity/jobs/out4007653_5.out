aa
bb
Combination: 0, 7
A
B
C
lh training
gnn: 0
layers: 7
trainlh.sh model is a pialgnn
----------------------------
Start loading dataset ...
numbers 100206
numbers 100307
numbers 100408
numbers 100610
numbers 101006
numbers 101107
numbers 101309
numbers 101410
numbers 101915
numbers 102008
numbers 102311
numbers 102513
numbers 102816
numbers 103111
numbers 103414
numbers 103515
numbers 103818
numbers 104012
numbers 104416
numbers 104820
numbers 105014
numbers 105115
numbers 105216
numbers 105620
numbers 105923
numbers 106016
numbers 106319
numbers 106521
numbers 107018
numbers 107220
numbers 107321
numbers 107422
numbers 107725
numbers 108121
numbers 108222
numbers 108323
numbers 108525
numbers 108828
numbers 109123
numbers 109325
numbers 109830
numbers 110007
numbers 110411
numbers 110613
numbers 111009
numbers 111312
numbers 111413
numbers 111514
numbers 111716
numbers 112112
numbers 112314
numbers 112516
numbers 112819
numbers 112920
numbers 113215
numbers 113619
numbers 113821
numbers 113922
numbers 114217
numbers 114318
numbers 114419
numbers 114621
numbers 114823
numbers 114924
numbers 115017
numbers 115219
numbers 115320
numbers 115825
numbers 116120
numbers 116221
numbers 116524
numbers 116726
numbers 117122
numbers 117324
numbers 117930
numbers 118023
numbers 118124
numbers 118225
numbers 118528
numbers 118730
numbers 118932
numbers 119126
numbers 119732
numbers 119833
numbers 120111
numbers 120212
numbers 120515
numbers 120717
numbers 121315
numbers 121416
numbers 121618
numbers 121820
numbers 121921
numbers 122317
numbers 122620
numbers 122822
numbers 123117
numbers 123420
numbers 123521
numbers 123824
numbers 123925
numbers 124220
numbers 124422
numbers 124624
numbers 124826
numbers 125525
numbers 126325
numbers 126628
numbers 126931
numbers 127327
numbers 127630
numbers 127933
numbers 128026
numbers 128127
numbers 128329
numbers 128632
numbers 128935
numbers 129028
numbers 129129
numbers 129331
numbers 129432
numbers 129533
numbers 129634
numbers 129937
numbers 130013
numbers 130316
numbers 130417
numbers 130619
numbers 130821
numbers 130922
numbers 131217
numbers 131419
numbers 131621
numbers 131722
numbers 131823
numbers 131924
numbers 132017
numbers 132118
numbers 133019
numbers 133625
numbers 133827
numbers 133928
numbers 134021
numbers 134223
numbers 134324
numbers 134425
numbers 134728
numbers 134829
numbers 135225
numbers 135528
numbers 135730
numbers 135932
numbers 136227
numbers 136732
numbers 136833
numbers 137027
numbers 137128
numbers 137229
numbers 137633
numbers 137936
numbers 138231
numbers 138534
numbers 138837
numbers 139233
numbers 139637
numbers 139839
numbers 140117
numbers 140319
numbers 140420
numbers 140824
numbers 140925
numbers 141119
numbers 141422
numbers 141826
numbers 142424
numbers 142828
numbers 143325
numbers 143426
numbers 143527
numbers 144125
numbers 144226
numbers 144428
numbers 144731
numbers 144832
numbers 145127
numbers 145531
numbers 145834
numbers 146129
numbers 146331
numbers 146432
numbers 146533
numbers 146634
numbers 146937
numbers 147030
numbers 147737
numbers 148032
numbers 148133
numbers 148335
numbers 148436
numbers 148840
numbers 148941
numbers 149236
numbers 149337
numbers 149539
numbers 149741
numbers 149842
numbers 150019
numbers 150423
numbers 150524
numbers 150625
numbers 150726
numbers 150928
numbers 151223
numbers 151425
numbers 151526
numbers 151627
numbers 151728
numbers 151829
numbers 152831
numbers 153025
numbers 153227
numbers 153429
numbers 153631
numbers 153732
numbers 153833
numbers 154229
numbers 154431
numbers 154532
numbers 154734
numbers 154835
numbers 154936
numbers 155231
numbers 155635
numbers 155938
numbers 156031
numbers 156233
numbers 156334
numbers 156435
numbers 156536
numbers 156637
numbers 157336
numbers 157437
numbers 157942
numbers 158035
numbers 158136
numbers 158338
numbers 158540
numbers 158843
numbers 159138
numbers 159239
numbers 159340
numbers 159441
numbers 159744
numbers 159845
numbers 159946
numbers 160123
numbers 160729
numbers 160830
numbers 160931
numbers 161327
numbers 161630
numbers 161731
numbers 162026
numbers 162228
numbers 162329
numbers 162733
numbers 162935
numbers 163129
numbers 163331
numbers 163432
numbers 163836
numbers 164030
numbers 164131
numbers 164636
numbers 164939
numbers 165032
numbers 165234
numbers 165638
numbers 165840
numbers 166438
numbers 166640
numbers 167036
numbers 167238
numbers 167743
numbers 168038
numbers 168139
numbers 168240
numbers 168341
numbers 168745
numbers 169141
numbers 169343
numbers 169444
numbers 169747
numbers 169949
numbers 170631
numbers 170934
numbers 171330
numbers 171431
numbers 171532
numbers 171633
numbers 172029
numbers 172130
numbers 172332
numbers 172433
numbers 172534
numbers 172938
numbers 173132
numbers 173233
numbers 173334
numbers 173435
numbers 173536
numbers 173637
numbers 173738
numbers 173839
numbers 173940
numbers 174437
numbers 174841
numbers 175035
numbers 175237
numbers 175338
numbers 175439
numbers 175540
numbers 175742
numbers 176037
numbers 176239
numbers 176441
numbers 176542
numbers 176744
numbers 177241
numbers 177342
numbers 177645
numbers 177746
numbers 178142
numbers 178243
numbers 178647
numbers 178748
numbers 178849
numbers 178950
numbers 179245
numbers 179346
numbers 179548
numbers 179952
numbers 180129
numbers 180432
numbers 180735
numbers 180836
numbers 180937
numbers 181131
numbers 181232
numbers 181636
numbers 182032
numbers 182436
numbers 182739
numbers 182840
numbers 183034
numbers 183337
numbers 185139
numbers 185341
numbers 185442
numbers 185846
numbers 185947
numbers 186141
numbers 186444
numbers 187143
numbers 187345
numbers 187547
numbers 187850
numbers 188347
numbers 188448
numbers 188549
numbers 188751
numbers 189349
numbers 189450
numbers 190031
numbers 190132
numbers 191033
numbers 191336
numbers 191437
numbers 191841
numbers 191942
numbers 192035
numbers 192136
numbers 192439
numbers 192540
numbers 192641
numbers 192843
numbers 193239
numbers 193441
numbers 194140
numbers 194645
numbers 194746
numbers 194847
numbers 195041
numbers 195445
numbers 195647
numbers 195849
numbers 195950
numbers 196144
numbers 196346
numbers 196750
numbers 197348
numbers 197449
numbers 197550
numbers 197651
numbers 198249
numbers 198350
numbers 198451
numbers 198653
numbers 198855
numbers 199150
numbers 199251
numbers 199453
numbers 199655
numbers 199958
numbers 300618
numbers 303119
numbers 303624
numbers 304020
numbers 304727
numbers 305830
numbers 307127
numbers 308129
numbers 308331
numbers 309636
numbers 310621
numbers 311320
numbers 316633
numbers 316835
numbers 317332
numbers 318637
numbers 320826
numbers 321323
numbers 322224
numbers 329440
numbers 330324
numbers 333330
numbers 334635
numbers 336841
numbers 339847
numbers 341834
numbers 346137
numbers 346945
numbers 348545
numbers 351938
numbers 352132
numbers 352738
numbers 353740
numbers 355239
numbers 355542
numbers 356948
numbers 358144
numbers 361234
numbers 361941
numbers 365343
numbers 366042
numbers 366446
numbers 371843
numbers 377451
numbers 378857
numbers 379657
numbers 380036
numbers 381038
numbers 381543
numbers 382242
numbers 385450
numbers 386250
numbers 387959
numbers 389357
numbers 390645
numbers 391748
numbers 393247
numbers 393550
numbers 395251
numbers 395756
numbers 395958
numbers 397154
numbers 397760
numbers 397861
numbers 406432
numbers 406836
numbers 412528
numbers 414229
numbers 415837
numbers 422632
numbers 424939
numbers 429040
numbers 432332
numbers 433839
numbers 436239
numbers 436845
numbers 441939
numbers 445543
numbers 448347
numbers 449753
numbers 453441
numbers 456346
numbers 459453
numbers 465852
numbers 467351
numbers 473952
numbers 475855
numbers 479762
numbers 480141
numbers 481951
numbers 485757
numbers 486759
numbers 492754
numbers 495255
numbers 497865
numbers 499566
numbers 500222
numbers 506234
numbers 510326
numbers 512835
numbers 513736
numbers 517239
numbers 519950
numbers 520228
numbers 521331
numbers 522434
numbers 523032
numbers 524135
numbers 525541
numbers 529549
numbers 529953
numbers 530635
numbers 531536
numbers 536647
numbers 540436
numbers 541943
numbers 545345
numbers 547046
numbers 548250
numbers 549757
numbers 552544
numbers 553344
numbers 555348
numbers 555651
numbers 557857
numbers 559053
numbers 561242
numbers 561444
numbers 562345
numbers 562446
numbers 565452
numbers 566454
numbers 567052
numbers 567961
numbers 568963
numbers 570243
numbers 571144
numbers 571548
numbers 572045
numbers 573249
numbers 573451
numbers 576255
numbers 579665
numbers 579867
numbers 580044
numbers 580347
numbers 580650
numbers 580751
numbers 581349
numbers 581450
numbers 583858
numbers 584355
numbers 585256
numbers 585862
numbers 586460
numbers 587664
numbers 588565
numbers 592455
numbers 594156
numbers 597869
numbers 598568
numbers 599065
numbers 599469
numbers 599671
numbers 601127
numbers 604537
numbers 609143
numbers 611231
numbers 611938
numbers 613235
numbers 613538
numbers 614439
numbers 615744
numbers 616645
numbers 617748
numbers 618952
numbers 620434
numbers 622236
numbers 623844
numbers 626648
numbers 627549
numbers 627852
numbers 628248
numbers 633847
numbers 638049
numbers 644044
numbers 645450
numbers 645551
numbers 647858
numbers 650746
numbers 654350
numbers 654754
numbers 656253
numbers 656657
numbers 657659
numbers 660951
numbers 662551
numbers 663755
numbers 664757
numbers 665254
numbers 667056
numbers 668361
numbers 671855
numbers 672756
numbers 673455
numbers 677766
numbers 677968
numbers 679568
numbers 679770
numbers 680250
numbers 680957
numbers 683256
numbers 685058
numbers 686969
numbers 687163
numbers 690152
numbers 693461
numbers 693764
numbers 695768
numbers 700634
numbers 702133
numbers 704238
numbers 705341
numbers 706040
numbers 707749
numbers 709551
numbers 713239
numbers 715041
numbers 715647
numbers 715950
numbers 720337
numbers 724446
numbers 725751
numbers 727553
numbers 727654
numbers 729254
numbers 729557
numbers 731140
numbers 732243
numbers 733548
numbers 734045
numbers 734247
numbers 735148
numbers 737960
numbers 742549
numbers 744553
numbers 745555
numbers 748258
numbers 748662
numbers 749058
numbers 749361
numbers 751348
numbers 751550
numbers 753150
numbers 753251
numbers 756055
numbers 759869
numbers 761957
numbers 765056
numbers 766563
numbers 767464
numbers 769064
numbers 770352
numbers 771354
numbers 773257
numbers 779370
numbers 782157
numbers 782561
numbers 783462
numbers 784565
numbers 786569
numbers 788876
numbers 789373
numbers 792564
numbers 792766
numbers 792867
numbers 793465
numbers 800941
numbers 802844
numbers 803240
numbers 810439
numbers 810843
numbers 812746
numbers 814649
numbers 816653
numbers 818859
numbers 820745
numbers 825048
numbers 826353
numbers 826454
numbers 833148
numbers 833249
numbers 835657
numbers 837560
numbers 837964
numbers 841349
numbers 843151
numbers 844961
numbers 845458
numbers 849264
numbers 849971
numbers 852455
numbers 856463
numbers 856766
numbers 856968
numbers 857263
numbers 859671
numbers 861456
numbers 865363
numbers 867468
numbers 870861
numbers 871762
numbers 871964
numbers 872158
numbers 872562
numbers 872764
numbers 873968
numbers 877168
numbers 877269
numbers 878776
numbers 880157
numbers 882161
numbers 885975
numbers 887373
numbers 889579
numbers 891667
numbers 894067
numbers 894673
numbers 894774
numbers 896778
numbers 896879
numbers 898176
numbers 899885
numbers 901038
numbers 901139
numbers 901442
numbers 904044
numbers 907656
numbers 910241
numbers 910443
numbers 912447
numbers 917255
numbers 917558
numbers 919966
numbers 922854
numbers 923755
numbers 926862
numbers 927359
numbers 930449
numbers 932554
numbers 937160
numbers 942658
numbers 947668
numbers 951457
numbers 952863
numbers 953764
numbers 955465
numbers 957974
numbers 958976
numbers 959574
numbers 965367
numbers 965771
numbers 966975
numbers 972566
numbers 978578
numbers 979984
numbers 983773
numbers 984472
numbers 987983
numbers 990366
numbers 991267
numbers 992673
numbers 992774
numbers 993675
numbers 994273
numbers 996782
MSE
Finish loading dataset. There are total 790 subjects.
Training data length 632
Validation data length 158
scaling factor  0.1
----------------------------
Start loading model ...
Model is CortexGNN
NLayerGCN 7
NLayerGCN 7
Finish loading model
----------------------------
Start training 200 epochs ...
Epoch:0, training loss:0.0389276229116264
----------------------------
Start validation ...
Validation error:0.030687265711117396
Validation error:0.030687265711117396
New best model saved at epoch 0 with validation error 0.030687265711117396
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 5.99 GiB
Finish validation.
----------------------------
Epoch:1, training loss:0.028498726926413896
Epoch:2, training loss:0.026276487429755965
Epoch:3, training loss:0.024803114518570372
Epoch:4, training loss:0.02398022077682935
Epoch:5, training loss:0.02328270153566912
Epoch:6, training loss:0.022507108146725577
Epoch:7, training loss:0.022188115991722747
Epoch:8, training loss:0.021539318186667145
Epoch:9, training loss:0.021253209024714895
Epoch:10, training loss:0.020819984892194596
----------------------------
Start validation ...
Validation error:0.02076536989947663
Validation error:0.02076536989947663
New best model saved at epoch 10 with validation error 0.02076536989947663
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 5.99 GiB
Finish validation.
----------------------------
Epoch:11, training loss:0.020637327867053166
Epoch:12, training loss:0.020216513802356357
Epoch:13, training loss:0.020008788725561638
Epoch:14, training loss:0.019906073229540657
Epoch:15, training loss:0.019689287316891117
Epoch:16, training loss:0.019509678015402883
Epoch:17, training loss:0.019423652584723467
Epoch:18, training loss:0.019200301172117455
Epoch:19, training loss:0.019096463631331637
Epoch:20, training loss:0.018925055095195015
----------------------------
Start validation ...
Validation error:0.019458741208986392
Validation error:0.019458741208986392
New best model saved at epoch 20 with validation error 0.019458741208986392
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 5.99 GiB
Finish validation.
----------------------------
Epoch:21, training loss:0.018744122057186462
Epoch:22, training loss:0.018673543548624067
Epoch:23, training loss:0.01866150506671895
Epoch:24, training loss:0.01855589294676445
Epoch:25, training loss:0.01842413400299847
Epoch:26, training loss:0.018283022118178255
Epoch:27, training loss:0.018238961925034564
Epoch:28, training loss:0.018225871299134118
Epoch:29, training loss:0.018097656830567632
Epoch:30, training loss:0.017976092668309147
----------------------------
Start validation ...
Validation error:0.019350046574880805
Validation error:0.019350046574880805
New best model saved at epoch 30 with validation error 0.019350046574880805
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 5.99 GiB
Finish validation.
----------------------------
Epoch:31, training loss:0.017909246825471615
Epoch:32, training loss:0.017803914136182562
Epoch:33, training loss:0.01778488013380549
Epoch:34, training loss:0.017636287310514365
Epoch:35, training loss:0.017538366025856025
Epoch:36, training loss:0.017562058272394293
Epoch:37, training loss:0.017378884046397442
Epoch:38, training loss:0.017499115415318293
Epoch:39, training loss:0.01727921786405665
Epoch:40, training loss:0.017355560031837396
----------------------------
Start validation ...
Validation error:0.01731304183036466
Validation error:0.01731304183036466
New best model saved at epoch 40 with validation error 0.01731304183036466
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 5.99 GiB
Finish validation.
----------------------------
Epoch:41, training loss:0.017284480558672943
Epoch:42, training loss:0.017228405218264912
Epoch:43, training loss:0.017157372806362713
Epoch:44, training loss:0.017132126702632332
Epoch:45, training loss:0.017114516749942698
Epoch:46, training loss:0.017005561607819096
Epoch:47, training loss:0.01699554507437905
Epoch:48, training loss:0.016956849655879166
Epoch:49, training loss:0.016815509345040575
Epoch:50, training loss:0.01682352836691786
----------------------------
Start validation ...
Validation error:0.01734214241298128
Validation error:0.01734214241298128
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 5.99 GiB
Finish validation.
----------------------------
Epoch:51, training loss:0.016830875172833853
Epoch:52, training loss:0.016755010766165826
Epoch:53, training loss:0.016759544437090997
Epoch:54, training loss:0.016715661794996433
Epoch:55, training loss:0.016703919461881152
Epoch:56, training loss:0.016614880001679346
Epoch:57, training loss:0.016534734263874685
Epoch:58, training loss:0.016573093921429465
Epoch:59, training loss:0.016471595706748245
Epoch:60, training loss:0.016489970661357895
----------------------------
Start validation ...
Validation error:0.017548943639886152
Validation error:0.017548943639886152
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 5.99 GiB
Finish validation.
----------------------------
Epoch:61, training loss:0.016517127918586418
Epoch:62, training loss:0.016546536238475032
Epoch:63, training loss:0.01635259677378956
Epoch:64, training loss:0.016307070864588494
Epoch:65, training loss:0.016340922234179097
Epoch:66, training loss:0.016342440477124402
Epoch:67, training loss:0.016265156189616346
Epoch:68, training loss:0.016234670323614454
Epoch:69, training loss:0.016227376088794744
Epoch:70, training loss:0.016194095331114492
----------------------------
Start validation ...
Validation error:0.016168524711569654
Validation error:0.016168524711569654
New best model saved at epoch 70 with validation error 0.016168524711569654
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 5.99 GiB
Finish validation.
----------------------------
Epoch:71, training loss:0.016164773488653045
Epoch:72, training loss:0.01624016668293861
Epoch:73, training loss:0.016085440250219706
Epoch:74, training loss:0.016062490328191483
Epoch:75, training loss:0.016006888185120836
Epoch:76, training loss:0.01604916535530098
Epoch:77, training loss:0.015995064793048498
Epoch:78, training loss:0.015943789808963767
Epoch:79, training loss:0.015895410541067773
Epoch:80, training loss:0.015912420045631596
----------------------------
Start validation ...
Validation error:0.015896365706679186
Validation error:0.015896365706679186
New best model saved at epoch 80 with validation error 0.015896365706679186
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 5.99 GiB
Finish validation.
----------------------------
Epoch:81, training loss:0.015941118090590345
Epoch:82, training loss:0.015834205038256093
Epoch:83, training loss:0.01590120672289565
Epoch:84, training loss:0.01592094314879962
Epoch:85, training loss:0.01588644414309035
Epoch:86, training loss:0.015874657763722294
Epoch:87, training loss:0.01576951007164213
Epoch:88, training loss:0.01577338566885719
Epoch:89, training loss:0.0157372263699322
Epoch:90, training loss:0.01571398883427293
----------------------------
Start validation ...
Validation error:0.01599941665566043
Validation error:0.01599941665566043
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 5.99 GiB
Finish validation.
----------------------------
Epoch:91, training loss:0.01575741231812848
Epoch:92, training loss:0.015707659486480813
Epoch:93, training loss:0.015641016699963168
Epoch:94, training loss:0.015721921091368777
Epoch:95, training loss:0.0156289564012373
Epoch:96, training loss:0.015639106967026674
Epoch:97, training loss:0.015610568754410348
Epoch:98, training loss:0.015542548633168769
Epoch:99, training loss:0.015600691226759006
Epoch:100, training loss:0.015640039272500274
----------------------------
Start validation ...
Validation error:0.015788357304055478
Validation error:0.015788357304055478
New best model saved at epoch 100 with validation error 0.015788357304055478
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 5.99 GiB
Finish validation.
----------------------------
Epoch:101, training loss:0.015494689277573666
Epoch:102, training loss:0.015483840633938206
Epoch:103, training loss:0.015472192349666847
Epoch:104, training loss:0.015478821200188956
Epoch:105, training loss:0.01545754875074129
Epoch:106, training loss:0.015420285575209728
Epoch:107, training loss:0.01541693670574953
Epoch:108, training loss:0.015433710047833716
Epoch:109, training loss:0.01538775130057165
Epoch:110, training loss:0.015373376548832541
----------------------------
Start validation ...
Validation error:0.0157090236692206
Validation error:0.0157090236692206
New best model saved at epoch 110 with validation error 0.0157090236692206
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 5.99 GiB
Finish validation.
----------------------------
Epoch:111, training loss:0.015365301295407589
Epoch:112, training loss:0.015365752317836578
Epoch:113, training loss:0.015269859960668167
Epoch:114, training loss:0.01529575201175824
Epoch:115, training loss:0.015313618937271494
Epoch:116, training loss:0.015285497672761543
Epoch:117, training loss:0.015180395549175012
Epoch:118, training loss:0.015229438097051145
Epoch:119, training loss:0.015309028946381958
Epoch:120, training loss:0.015213621749330454
----------------------------
Start validation ...
Validation error:0.015724530343343562
Validation error:0.015724530343343562
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 5.99 GiB
Finish validation.
----------------------------
Epoch:121, training loss:0.015271612359034015
Epoch:122, training loss:0.015195555875926643
Epoch:123, training loss:0.015222899239993643
Epoch:124, training loss:0.015213382748674743
Epoch:125, training loss:0.015250387044529183
Epoch:126, training loss:0.015172590119941043
Epoch:127, training loss:0.015089492325352716
Epoch:128, training loss:0.015132407650434047
Epoch:129, training loss:0.015079456850108279
Epoch:130, training loss:0.015094835485060569
----------------------------
Start validation ...
Validation error:0.016221143906535226
Validation error:0.016221143906535226
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 5.99 GiB
Finish validation.
----------------------------
Epoch:131, training loss:0.015135962738584774
Epoch:132, training loss:0.015068642084805083
Epoch:133, training loss:0.015020908591856213
Epoch:134, training loss:0.015063255911846233
Epoch:135, training loss:0.015027010188544099
Epoch:136, training loss:0.015075142950680154
Epoch:137, training loss:0.015005345761339781
Epoch:138, training loss:0.014958230741734652
Epoch:139, training loss:0.015022338413680562
Epoch:140, training loss:0.01501103544230514
----------------------------
Start validation ...
Validation error:0.015444004872837399
Validation error:0.015444004872837399
New best model saved at epoch 140 with validation error 0.015444004872837399
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 5.99 GiB
Finish validation.
----------------------------
Epoch:141, training loss:0.014916485306641818
Epoch:142, training loss:0.014945368743737381
Epoch:143, training loss:0.014909639208919452
Epoch:144, training loss:0.014949467289556243
Epoch:145, training loss:0.015042447429032454
Epoch:146, training loss:0.014906159059816524
Epoch:147, training loss:0.014873489380896658
Epoch:148, training loss:0.01489828486891487
Epoch:149, training loss:0.014887357487260729
Epoch:150, training loss:0.014940433245435168
----------------------------
Start validation ...
Validation error:0.015714712323078625
Validation error:0.015714712323078625
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 5.99 GiB
Finish validation.
----------------------------
Epoch:151, training loss:0.014959862684135478
Epoch:152, training loss:0.014857545024951142
Epoch:153, training loss:0.014818094689929505
Epoch:154, training loss:0.014818475774748699
Epoch:155, training loss:0.014842360077095749
Epoch:156, training loss:0.014805983647385824
Epoch:157, training loss:0.014821431680606042
Epoch:158, training loss:0.014810330521822259
Epoch:159, training loss:0.014742121997855226
Epoch:160, training loss:0.014756369684480979
----------------------------
Start validation ...
Validation error:0.015149621234004255
Validation error:0.015149621234004255
New best model saved at epoch 160 with validation error 0.015149621234004255
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 5.99 GiB
Finish validation.
----------------------------
Epoch:161, training loss:0.014704149407983015
Epoch:162, training loss:0.014775319449320624
Epoch:163, training loss:0.014798875248260042
Epoch:164, training loss:0.014744469113471104
Epoch:165, training loss:0.01475566064149047
Epoch:166, training loss:0.014695545774884522
Epoch:167, training loss:0.014650781467981353
Epoch:168, training loss:0.014709876443530563
Epoch:169, training loss:0.01469897772509699
Epoch:170, training loss:0.014678452477813993
----------------------------
Start validation ...
Validation error:0.015206478164778858
Validation error:0.015206478164778858
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 5.99 GiB
Finish validation.
----------------------------
Epoch:171, training loss:0.014688549692966516
Epoch:172, training loss:0.014703350596990484
Epoch:173, training loss:0.014669777141718925
Epoch:174, training loss:0.014689582360236422
Epoch:175, training loss:0.014652979935967375
Epoch:176, training loss:0.01458763011106396
Epoch:177, training loss:0.014632686126765005
Epoch:178, training loss:0.014630187295459778
Epoch:179, training loss:0.014593633050924237
Epoch:180, training loss:0.01457161115647494
----------------------------
Start validation ...
Validation error:0.014999100926650476
Validation error:0.014999100926650476
New best model saved at epoch 180 with validation error 0.014999100926650476
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 5.99 GiB
Finish validation.
----------------------------
Epoch:181, training loss:0.01463598076142135
Epoch:182, training loss:0.014576538682538026
Epoch:183, training loss:0.014641057584977036
Epoch:184, training loss:0.014519780893409271
Epoch:185, training loss:0.014585701962402444
Epoch:186, training loss:0.014540006372712175
Epoch:187, training loss:0.01459811540627027
Epoch:188, training loss:0.014517994904065435
Epoch:189, training loss:0.014570105305130157
Epoch:190, training loss:0.01445319818751297
----------------------------
Start validation ...
Validation error:0.014994563422861356
Validation error:0.014994563422861356
New best model saved at epoch 190 with validation error 0.014994563422861356
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 5.99 GiB
Finish validation.
----------------------------
Epoch:191, training loss:0.01449491302011228
Epoch:192, training loss:0.014467395105269513
Epoch:193, training loss:0.014479654942804216
Epoch:194, training loss:0.014537332339294821
Epoch:195, training loss:0.014507718730564641
Epoch:196, training loss:0.01443444220260776
Epoch:197, training loss:0.014464946804108404
Epoch:198, training loss:0.01449324987545798
Epoch:199, training loss:0.014397642504471012
Epoch:200, training loss:0.014355960870868986
----------------------------
Start validation ...
Validation error:0.014836418006239058
Validation error:0.014836418006239058
New best model saved at epoch 200 with validation error 0.014836418006239058
Save model checkpoints ... 
Save pial surface mesh ... 
Maximum allocated GPU memory: 5.99 GiB
Finish validation.
----------------------------
Finish training.
----------------------------
D
CC
